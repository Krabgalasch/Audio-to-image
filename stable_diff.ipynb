{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flax diffusers transformers ftfy stable_diffusion_videos yt-dlp -q\n",
    "import jax; jax.devices()\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_duration = 45 # time in seconds of the video\n",
    "fps = 30\n",
    "repeat_prompts_every = 2 # time in seconds of how long to wait between prompts before a different image using the same prompt is generated \n",
    "time_per_transition = 0.5 # time in seconds to transition between different prompts\n",
    "\n",
    "text_transcript = [\n",
    "      # PUT TEXT TRANSCRIPT HERE\n",
    "(0, 'Goat'),\n",
    "(1.68, 'animal'),\n",
    "(2.16, 'water'),\n",
    "(3.08, 'goat man'),\n",
    "(5.2, 'jumping from the city skyline'),\n",
    "(9.04, 'Jesus Christ'),\n",
    "(10.68, 'keine'),\n",
    "(11.38, 'beiden Sprachen'),\n",
    "(15.2, 'irgendwelchen Worten'),\n",
    "(19.26, 'Obama'),\n",
    "(19.86, 'Bush'),\n",
    "(19.98, 'nein'),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Goat', 'Goat', 'animal', 'animal', 'water', 'water', 'goat man', 'goat man', 'jumping from the city skyline', 'jumping from the city skyline', 'jumping from the city skyline', 'Jesus Christ', 'Jesus Christ', 'keine', 'keine', 'beiden Sprachen', 'beiden Sprachen', 'beiden Sprachen', 'irgendwelchen Worten', 'irgendwelchen Worten', 'irgendwelchen Worten', 'Obama', 'Obama', 'Bush', 'Bush', 'nein', 'nein', 'nein', 'nein', 'nein', 'nein', 'nein', 'nein', 'nein', 'nein', 'nein', 'nein', 'nein', 'nein']\n",
      "[35, 15, 59, 15, 12, 15, 48, 15, 60, 40, 15, 34, 15, 6, 15, 60, 39, 15, 60, 46, 15, 2, 15, 48, 15, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 30]\n",
      "[2996, 3007, 89284, 9709, 59780, 92802, 87183, 93793, 31348, 62135, 86347, 21889, 44113, 27862, 86253, 21111, 11172, 61729, 69962, 94569, 86136, 86437, 25667, 59322, 75066, 15852, 9423, 58839, 58756, 37922, 35766, 62233, 66622, 38914, 68764, 79405, 9956, 2345, 98483]\n"
     ]
    }
   ],
   "source": [
    "prompts = []\n",
    "num_interpolation_steps = []\n",
    "\n",
    "for idx, (start, text) in enumerate(text_transcript):\n",
    "    if idx == len(text_transcript) - 1:\n",
    "        end = video_duration\n",
    "    else:\n",
    "        end = text_transcript[idx+1][0]\n",
    "\n",
    "    duration = end - start\n",
    "    prompt_repeats = int((duration - time_per_transition) // repeat_prompts_every)\n",
    "    remainder_prompt_time = (duration - time_per_transition) % repeat_prompts_every\n",
    "\n",
    "    prompts += [text] * prompt_repeats\n",
    "    num_interpolation_steps += [fps * repeat_prompts_every] * prompt_repeats\n",
    "\n",
    "    if int(remainder_prompt_time * fps) != 0:\n",
    "        prompts.append(text)\n",
    "        num_interpolation_steps.append(int(remainder_prompt_time * fps))\n",
    "\n",
    "    num_interpolation_steps.append(fps//2)\n",
    "    prompts.append(text)\n",
    "\n",
    "num_interpolation_steps = num_interpolation_steps[:-1]\n",
    "num_interpolation_steps[-1] += int(time_per_transition * fps)\n",
    "\n",
    "seeds = [random.randint(0, 100000) for _ in range(len(prompts))]\n",
    "print(prompts)\n",
    "print(num_interpolation_steps)\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FlaxStableDiffusionWalkPipeline', 'Interface', 'RealESRGANModel', 'StableDiffusionWalkPipeline', 'generate_images', 'generate_images_flax', 'get_timesteps_arr', 'make_video_pyav', 'upload_folder_chunked']\n"
     ]
    }
   ],
   "source": [
    "import stable_diffusion_videos\n",
    "print(dir(stable_diffusion_videos))\n",
    "\n",
    "from stable_diffusion_videos.pipelines import StableDiffusionWalkPipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StableDiffusionWalkPipeline' from 'stable_diffusion_videos' (d:\\Anaconda\\envs\\stable_diff\\lib\\site-packages\\stable_diffusion_videos\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\soundtoimage\\stable_diff.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstable_diffusion_videos\u001b[39;00m \u001b[39mimport\u001b[39;00m StableDiffusionWalkPipeline\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m hf_hub_download\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StableDiffusionWalkPipeline' from 'stable_diffusion_videos' (d:\\Anaconda\\envs\\stable_diff\\lib\\site-packages\\stable_diffusion_videos\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from stable_diffusion_videos import StableDiffusionWalkPipeline\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "\n",
    "pipeline = StableDiffusionWalkPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "    torch_dtype=torch.float16,\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Seconds in the song.\n",
    "audio_offsets = [146, 148]  # [Start, end]\n",
    "fps = 30  # Use lower values for testing (5 or 10), higher values for better quality (30 or 60)\n",
    "\n",
    "# Convert seconds to frames\n",
    "num_interpolation_steps = [(b-a) * fps for a, b in zip(audio_offsets, audio_offsets[1:])]\n",
    "\n",
    "video_path = pipeline.walk(\n",
    "    prompts=prompts,\n",
    "    seeds=seeds,\n",
    "    num_interpolation_steps=num_interpolation_steps,\n",
    "    audio_filepath='recorded.mp3',\n",
    "    audio_start_sec=audio_offsets[0],\n",
    "    fps=fps,\n",
    "    height=512,  # use multiples of 64 if > 512. Multiples of 8 if < 512.\n",
    "    width=512,   # use multiples of 64 if > 512. Multiples of 8 if < 512.\n",
    "    output_dir='dreams',        # Where images/videos will be saved\n",
    "    guidance_scale=7.5,         # Higher adheres to prompt more, lower lets model take the wheel\n",
    "    num_inference_steps=50,     # Number of diffusion steps per image generated. 50 is good default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\soundtoimage\\stable_diff.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Set the output directory to the current working directory\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m output_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetcwd()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m video_path \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mwalk(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     p_params,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     prompts,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     seeds,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     fps\u001b[39m=\u001b[39mfps,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     num_interpolation_steps\u001b[39m=\u001b[39mnum_interpolation_steps,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     output_dir\u001b[39m=\u001b[39moutput_dir,  \u001b[39m# Save the video in the current working directory\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     jit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     guidance_scale\u001b[39m=\u001b[39m\u001b[39m7.5\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     num_inference_steps\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m toc \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/soundtoimage/stable_diff.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVideo saved at: \u001b[39m\u001b[39m{\u001b[39;00mvideo_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "# Set the output directory to the current working directory\n",
    "output_dir = os.getcwd()\n",
    "\n",
    "video_path = pipeline.walk(\n",
    "    p_params,\n",
    "    prompts,\n",
    "    seeds,\n",
    "    fps=fps,\n",
    "    num_interpolation_steps=num_interpolation_steps,\n",
    "    output_dir=output_dir,  # Save the video in the current working directory\n",
    "    jit=True,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=20,\n",
    ")\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(f\"Video saved at: {video_path}\")\n",
    "print(f\"Time taken to generate video: {toc - tic} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_diff_videos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
